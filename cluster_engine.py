# -*- coding: utf-8 -*-
"""cluster_engine.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a0405mC_dX_9ZoSDz5PDTApgYYLg2ZGw
"""

import argparse
import sys
import os
import glob
import json
import numpy as np
import cv2
from PIL import Image
from tqdm import tqdm
from ultralytics import YOLO
import torch
import clip
from cv2 import dnn_superres

# ML Libraries
from sklearn.preprocessing import normalize
from sklearn.decomposition import PCA
import umap
from sklearn.cluster import DBSCAN
from kneed import KneeLocator
from sklearn.neighbors import NearestNeighbors

def main():
    parser = argparse.ArgumentParser(description="AI Hybrid Clustering Engine (SR+YOLO+CLIP)")
    parser.add_argument('--image_dir', type=str, required=True, help="Input image directory")
    parser.add_argument('--output', type=str, required=True, help="Output JSON path")
    args = parser.parse_args()

    # 1. Load Models
    print("[SYSTEM] Loading AI Models...")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"[INFO] Processing Device: {device}")

    # Load YOLOv10s
    try:
        yolo_model = YOLO('yolov10s.pt')
    except:
        print("[INFO] Downloading YOLOv10s...")
        yolo_model = YOLO('yolov10s.pt')

    # Load CLIP
    print("[INFO] Loading CLIP model (ViT-B/32)...")
    clip_model, preprocess = clip.load("ViT-B/32", device=device)

    # Load EDSR (Super Resolution)
    model_path = "EDSR_x3.pb"
    if not os.path.exists(model_path):
        print("[INFO] Downloading EDSR_x3 model...")
        os.system("wget -O EDSR_x3.pb https://github.com/Saafke/EDSR_Tensorflow/raw/master/models/EDSR_x3.pb")

    sr = dnn_superres.DnnSuperResImpl_create()
    sr.readModel(model_path)
    sr.setModel("edsr", 3)

    # 2. Feature Extraction Loop
    image_paths = []
    # Support multiple extensions
    for ext in ('*.jpg', '*.jpeg', '*.png', '*.bmp', '*.webp'):
        image_paths.extend(glob.glob(os.path.join(args.image_dir, '**', ext), recursive=True))

    if not image_paths:
        print("[ERROR] No images found.")
        return

    print(f"[SYSTEM] Processing {len(image_paths)} images (Conditional SR + Hybrid Extraction)...")
    features = []
    valid_paths = []

    for img_path in tqdm(image_paths):
        try:
            # A. Upscale Logic (Modified)
            cv_img = cv2.imread(img_path)
            if cv_img is None: continue

            h, w, _ = cv_img.shape

            # [Fix] Only upscale if the image is small (< 128px)
            # This prevents memory overflow and long processing time for high-res images.
            if h < 128 or w < 128:
                upscaled = sr.upsample(cv_img)
                original_img = Image.fromarray(cv2.cvtColor(upscaled, cv2.COLOR_BGR2RGB))
            else:
                original_img = Image.fromarray(cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB))

            # B. Detect & Crop
            results = yolo_model(original_img, verbose=False, conf=0.25, device='cpu')
            result = results[0]
            target_img = None

            if hasattr(result, 'boxes') and len(result.boxes) > 0:
                box = result.boxes.xyxy[0].cpu().numpy().astype(int)
                w_img, h_img = original_img.size
                x1, y1 = max(0, box[0]), max(0, box[1])
                x2, y2 = min(w_img, box[2]), min(h_img, box[3])

                # Crop if valid size (>30px)
                if (x2 - x1) > 30 and (y2 - y1) > 30:
                    target_img = original_img.crop((x1, y1, x2, y2))

            if target_img is None:
                target_img = original_img

            # C. Embed with CLIP
            image_input = preprocess(target_img).unsqueeze(0).to(device)
            with torch.no_grad():
                vec = clip_model.encode_image(image_input).cpu().numpy().flatten()

            features.append(vec)
            valid_paths.append(os.path.relpath(img_path, args.image_dir))

        except Exception:
            continue

    if len(features) < 5:
        print("[ERROR] Not enough data to cluster (minimum 5 required).")
        return

    # 3. Clustering Pipeline
    X = np.array(features)
    n_total = X.shape[0]

    # Auto-configure min_samples
    if n_total < 200: min_samples = 3
    elif n_total < 1000: min_samples = 5
    else: min_samples = 10

    print(f"[SYSTEM] Clustering (min_samples={min_samples})...")

    # Dimensionality Reduction
    X_norm = normalize(X, norm='l2')
    pca = PCA(n_components=0.95, random_state=42)
    X_pca = pca.fit_transform(X_norm)

    reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=3, metric='cosine', random_state=42)
    X_umap = reducer.fit_transform(X_pca)

    # Auto-Eps Calculation
    nn = NearestNeighbors(n_neighbors=min_samples)
    nn.fit(X_umap)
    k_distances = np.sort(nn.kneighbors(X_umap)[0][:, min_samples-1])

    try:
        kneedle = KneeLocator(range(len(k_distances)), k_distances, curve='convex', direction='increasing')
        eps = kneedle.elbow_y
        if eps is None: eps = 0.5
    except:
        eps = 0.5
    if eps > 1.0: eps = 0.5

    # DBSCAN with Retry Logic
    final_labels = []
    for attempt in range(1, 4):
        dbscan = DBSCAN(eps=eps, min_samples=min_samples)
        labels = dbscan.fit_predict(X_umap)

        # Check if clusters are formed (excluding noise)
        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
        if n_clusters >= 2:
            final_labels = labels
            break
        eps *= 0.6 # Reduce eps to split clusters

    if len(final_labels) == 0: final_labels = labels

    # 4. Quality & Label Processing
    print("[SYSTEM] Generating Output JSON...")

    # Quality Check
    unique_groups = set(final_labels) - {-1}
    group_spreads = []
    for g in unique_groups:
        idx = [i for i, x in enumerate(final_labels) if x == g]
        pts = X_umap[idx]
        if len(pts) > 1:
            spread = np.mean(np.linalg.norm(pts - np.mean(pts, axis=0), axis=1))
            group_spreads.append(spread)

    thresh = np.mean(group_spreads) * 1.2 if group_spreads else 0.5
    quality_map = {}
    for g in unique_groups:
        idx = [i for i, x in enumerate(final_labels) if x == g]
        pts = X_umap[idx]
        spread = np.mean(np.linalg.norm(pts - np.mean(pts, axis=0), axis=1))
        quality_map[g] = 'low' if spread > thresh else 'high'

    # Save Results
    results = []
    for i in range(len(valid_paths)):
        g_id = int(final_labels[i])
        qual = 'low' if g_id == -1 else quality_map.get(g_id, 'high')

        # Extract Label from Filename for Search Feature
        filename = os.path.basename(valid_paths[i])
        if "_" in filename:
            label = filename.split('_')[0]
        else:
            label = "Unknown"

        results.append({
            "filename": valid_paths[i],
            "label": label,
            "x": float(X_umap[i, 0]),
            "y": float(X_umap[i, 1]),
            "z": float(X_umap[i, 2]),
            "group": g_id,
            "quality": qual
        })

    with open(args.output, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=4, ensure_ascii=False)

    print(f"[SUCCESS] Results saved to {args.output}")

if __name__ == "__main__":
    main()